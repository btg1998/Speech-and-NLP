{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport sys\\norig_stdout = sys.stdout\\nf = open('output.txt', 'w')\\nsys.stdout = f\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "f = open('output.txt', 'w')\n",
    "sys.stdout = f\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\bharg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(brown.sents()[0:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [token.lower() for token in sentences[i]]\n",
    "for i in range(len(sentences)):\n",
    "    p=[]\n",
    "    for j in range(len(sentences[i])):\n",
    "        if sentences[i][j].isalpha()==True:\n",
    "            p.append(sentences[i][j])\n",
    "    sentences[i]=p\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i]=' '.join(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, ngrams, trigrams \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope and Intercept for log-log plot for zipfs law in unigrams\n",
      "-0.7294188985606873 4.485539390443362\n"
     ]
    }
   ],
   "source": [
    "# Verification of Zipf's Law for Unigrams\n",
    "unigrams=[]\n",
    "for elem in sentences:\n",
    "    unigrams.extend(elem.split())\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(unigrams)\n",
    "import pylab\n",
    "import math\n",
    "from scipy import stats\n",
    "words = fdist.most_common()\n",
    "x = [math.log10(i[1]) for i in words]\n",
    "y = [math.log10(i) for i in range(1, len(x))]\n",
    "x.pop()\n",
    "(m, b) = pylab.polyfit(x, y, 1)\n",
    "yp = pylab.polyval([m, b], x)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print('Slope and Intercept for log-log plot for zipfs law in unigrams')\n",
    "print(slope,intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28aa5360208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Unigram Zipf's Law\n",
    "pylab.plot(x, yp)\n",
    "pylab.scatter(x, y)\n",
    "pylab.ylim([min(y), max(y)])\n",
    "pylab.xlim([min(x), max(x)])\n",
    "pylab.grid(True)\n",
    "pylab.ylabel('Counts of words')\n",
    "pylab.xlabel('Ranks of words')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams with count\n",
      "[('the', 56448), ('of', 31276), ('and', 22091), ('to', 20335), ('in', 17696), ('a', 17641), ('is', 9474), ('that', 8240), ('for', 7787), ('it', 6051)]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 Unigrams\n",
    "print('Top 10 Unigrams with count')\n",
    "print(words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Make Bigram Model from Sentences\n",
    "def bigram_model(sentences):\n",
    "    model={}\n",
    "    for sent in sentences:\n",
    "         for w1,w2 in ngrams(sent.split(),2, pad_left=True,pad_right=True):\n",
    "            if w1 not in model:\n",
    "                model[w1]={}\n",
    "            if w2 not in model[w1]:\n",
    "                model[w1][w2]=0\n",
    "            model[w1][w2]+=1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope and Intercept for log-log plot for zipfs law in bigrams\n",
      "-1.4104530417477712 5.2802626901581\n"
     ]
    }
   ],
   "source": [
    "# Verification of Zipf's Law for Bigrams\n",
    "bigram=bigram_model(sentences)\n",
    "built_bigram={}\n",
    "for i in bigram.keys():\n",
    "    for j in bigram[i].keys():\n",
    "        built_bigram[str(i)+' '+str(j)]=bigram[i][j]\n",
    "from nltk.probability import FreqDist\n",
    "fdist2 = FreqDist(built_bigram)\n",
    "import pylab\n",
    "import math\n",
    "from scipy import stats\n",
    "words = fdist2.most_common()\n",
    "x = [math.log10(i[1]) for i in words]\n",
    "y = [math.log10(i) for i in range(1, len(x))]\n",
    "x.pop()\n",
    "(m, b) = pylab.polyfit(x, y, 1)\n",
    "yp = pylab.polyval([m, b], x)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print('Slope and Intercept for log-log plot for zipfs law in bigrams')\n",
    "print(slope,intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28aa953e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Bigram Zipf's Law\n",
    "pylab.plot(x, yp)\n",
    "pylab.scatter(x, y)\n",
    "pylab.ylim([min(y), max(y)])\n",
    "pylab.xlim([min(x), max(x)])\n",
    "pylab.grid(True)\n",
    "pylab.ylabel('Counts of bigrams')\n",
    "pylab.xlabel('Ranks of bigrams')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Bigrams with count when None allowed\n",
      "[('of the', 8516), ('None the', 5820), ('in the', 4992), ('to the', 2825), ('and the', 1864), ('on the', 1824), ('for the', 1592), ('None in', 1589), ('None it', 1519), ('it is', 1390)]\n"
     ]
    }
   ],
   "source": [
    "# None corresponds to the pad\n",
    "# Top 10 Bigrams with None allowed\n",
    "print('Top 10 Bigrams with count when None allowed')\n",
    "print(words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Bigrams with count when None not allowed\n",
      "[('of the', 8516), ('in the', 4992), ('to the', 2825), ('and the', 1864), ('on the', 1824), ('for the', 1592), ('it is', 1390), ('to be', 1373), ('with the', 1262), ('that the', 1244)]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 Bigrams without None \n",
    "print('Top 10 Bigrams with count when None not allowed')\n",
    "ans=[]\n",
    "for i in words:\n",
    "    if 'None' not in i[0]:\n",
    "        ans.append(i)\n",
    "    if len(ans)==10:\n",
    "        break\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make Trigram Model from Sentences\n",
    "def trigram_model(sentences):\n",
    "    model={}\n",
    "    for sent in sentences:\n",
    "         for w1,w2,w3 in ngrams(sent.split(),3, pad_left=True,pad_right=True):\n",
    "            if (w1,w2) not in model:\n",
    "                model[(w1,w2)]={}\n",
    "            if w3 not in model[(w1,w2)]:\n",
    "                model[(w1,w2)][w3]=0\n",
    "            model[(w1,w2)][w3]+=1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope and Intercept for log-log plot for zipfs law in trigrams\n",
      "-2.1975922562310486 5.467006145296135\n"
     ]
    }
   ],
   "source": [
    "# Verification of Zipf's Law for Trigrams\n",
    "trigram=trigram_model(sentences)\n",
    "built_trigram={}\n",
    "for i in trigram.keys():\n",
    "    for j in trigram[i].keys():\n",
    "        built_trigram[str(i[0])+' '+str(i[1])+' '+str(j)]=trigram[i][j]\n",
    "from nltk.probability import FreqDist\n",
    "fdist3 = FreqDist(built_trigram)\n",
    "import pylab\n",
    "import math\n",
    "from scipy import stats\n",
    "words = fdist3.most_common()\n",
    "x = [math.log10(i[1]) for i in words]\n",
    "y = [math.log10(i) for i in range(1, len(x))]\n",
    "x.pop()\n",
    "(m, b) = pylab.polyfit(x, y, 1)\n",
    "yp = pylab.polyval([m, b], x)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print('Slope and Intercept for log-log plot for zipfs law in trigrams')\n",
    "print(slope,intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28aa743c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zipf's Law plot for Trigrams\n",
    "pylab.plot(x, yp)\n",
    "pylab.scatter(x, y)\n",
    "pylab.ylim([min(y), max(y)])\n",
    "pylab.xlim([min(x), max(x)])\n",
    "pylab.grid(True)\n",
    "pylab.ylabel('Counts of trigrams')\n",
    "pylab.xlabel('Ranks of trigrams')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Trigrams with count when None allowed\n",
      "[('None None the', 5820), ('None None in', 1589), ('None None it', 1519), ('None None he', 1377), ('None None this', 1054), ('None None but', 1038), ('None None None', 998), ('None None a', 980), ('None None and', 867), ('None None i', 675)]\n"
     ]
    }
   ],
   "source": [
    "# None corresponds to the pad\n",
    "# Top 10 Trigrams with None allowed\n",
    "print('Top 10 Trigrams with count when None allowed')\n",
    "print(words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Trigrams with count when None not allowed\n",
      "[('one of the', 337), ('the united states', 333), ('as well as', 225), ('some of the', 156), ('the fact that', 154), ('part of the', 131), ('of the united', 128), ('it is not', 126), ('a number of', 119), ('there is a', 118)]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 Trigrams without None \n",
    "print('Top 10 Trigrams with count when None not allowed')\n",
    "ans=[]\n",
    "for i in words:\n",
    "    if 'None' not in i[0]:\n",
    "        ans.append(i)\n",
    "    if len(ans)==10:\n",
    "        break\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Models of Count to Models of Probabilities\n",
    "\n",
    "from collections import Counter\n",
    "unigram=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "\n",
    "for word in unigram:\n",
    "    unigram[word]/=unigram_total\n",
    "\n",
    "for w1 in bigram:\n",
    "        tot_count=float(sum(bigram[w1].values()))\n",
    "        for w2 in bigram[w1]:\n",
    "            bigram[w1][w2]/=tot_count\n",
    "\n",
    "for (w1,w2) in trigram:\n",
    "        tot_count=float(sum(trigram[(w1,w2)].values()))\n",
    "        for w3 in trigram[(w1,w2)]:\n",
    "            trigram[(w1,w2)][w3]/=tot_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"test_examples.txt\", \"r\")\n",
    "test_sentences=text_file.read().split('\\n')\n",
    "# test_sentences=['he lived a good life','the man was happy','the person was good','the girl was sad','he won the war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Test\n",
      "The sequence he lived a good life has perplexity of 677.7331175727362\n",
      "The sequence the man was happy has perplexity of 393.42927411327105\n",
      "The sequence the person was good has perplexity of 332.3124643009282\n",
      "The sequence the girl was sad has perplexity of 883.0764781243006\n",
      "The sequence he won the war has perplexity of 462.03024050657456\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram Test\")\n",
    "#computes perplexity of the unigram model on a testset  \n",
    "def uniperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for word in testset:\n",
    "        N += 1\n",
    "        perplexity = perplexity * (1/model[word])\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, unigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Test\n",
      "The sequence he lived a good life has perplexity of 85.84319272687979\n",
      "The sequence the man was happy has perplexity of 80.4126602053961\n",
      "The sequence the person was good has perplexity of 142.25717469980296\n",
      "The sequence the girl was sad has perplexity of inf\n",
      "The sequence he won the war has perplexity of 64.26020284387174\n"
     ]
    }
   ],
   "source": [
    "print('Bigram Test')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def biperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            model[testset[i-1]][testset[i]]\n",
    "        except KeyError:\n",
    "            perplexity=math.inf\n",
    "            break\n",
    "        perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(biperplexity(i, bigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Test\n",
      "The sequence he lived a good life has perplexity of inf\n",
      "The sequence the man was happy has perplexity of inf\n",
      "The sequence the person was good has perplexity of inf\n",
      "The sequence the girl was sad has perplexity of inf\n",
      "The sequence he won the war has perplexity of 14.018332988300738\n"
     ]
    }
   ],
   "source": [
    "print('Trigram Test')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def triperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + [None] + testset + [None] + [None] \n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            model[(testset[i-2],testset[i-1])][testset[i]]\n",
    "        except KeyError:\n",
    "            perplexity=math.inf\n",
    "            break\n",
    "        perplexity = perplexity * (1/model[(testset[i-2],testset[i-1])][testset[i]])\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(triperplexity(i, trigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram test \n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.5938\n",
      "The sequence the man was happy has unigram log-likelihood of -23.8996\n",
      "The sequence the person was good has unigram log-likelihood of -23.2243\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.1336\n",
      "The sequence he won the war has unigram log-likelihood of -24.5425\n",
      "\n",
      "Bigram test \n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -26.7151\n",
      "The sequence the man was happy has bigram log-likelihood of -21.9359\n",
      "The sequence the person was good has bigram log-likelihood of -24.7882\n",
      "The sequence the girl was sad has bigram log-likelihood of -inf\n",
      "The sequence he won the war has bigram log-likelihood of -20.8147\n",
      "\n",
      "Trigram test \n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -inf\n",
      "The sequence the man was happy has trigram log-likelihood of -inf\n",
      "The sequence the person was good has trigram log-likelihood of -inf\n",
      "The sequence the girl was sad has trigram log-likelihood of -inf\n",
      "The sequence he won the war has trigram log-likelihood of -15.8422\n"
     ]
    }
   ],
   "source": [
    "# Calculating Log likehoods of each model on Test Data\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "print('Unigram test \\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(unigram[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,4)))\n",
    "\n",
    "\n",
    "print('\\nBigram test \\n')\n",
    "test_bigram_arr=[]\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            bigram[w1][w2]\n",
    "        except KeyError:\n",
    "            p_val=-1*math.inf\n",
    "            break\n",
    "        p_val+=math.log(bigram[w1][w2])\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,4)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test \\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(trigram[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            p_val=-1*math.inf\n",
    "            break\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,4)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts Models\n",
    "bigram_counts=bigram_model(sentences)\n",
    "trigram_counts=trigram_model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing with k=1\n",
      "Unigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.80237583\n",
      "The sequence the man was happy has unigram log-likelihood of -24.06386777\n",
      "The sequence the person was good has unigram log-likelihood of -23.39853251\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.24934479\n",
      "The sequence he won the war has unigram log-likelihood of -24.70738218\n",
      "\n",
      "Bigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -43.66615774\n",
      "The sequence the man was happy has bigram log-likelihood of -34.8631562\n",
      "The sequence the person was good has bigram log-likelihood of -36.54954686\n",
      "The sequence the girl was sad has bigram log-likelihood of -40.5430167\n",
      "The sequence he won the war has bigram log-likelihood of -34.35564902\n",
      "\n",
      "Trigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -60.0475751\n",
      "The sequence the man was happy has trigram log-likelihood of -48.42203672\n",
      "The sequence the person was good has trigram log-likelihood of -49.33189563\n",
      "The sequence the girl was sad has trigram log-likelihood of -52.35097309\n",
      "The sequence he won the war has trigram log-likelihood of -47.3550479\n",
      "\n",
      "Unigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 706.6073710835825\n",
      "The sequence the man was happy has perplexity of 409.92201814722625\n",
      "The sequence the person was good has perplexity of 347.10701343216573\n",
      "The sequence the girl was sad has perplexity of 908.9919125530047\n",
      "The sequence he won the war has perplexity of 481.47078001809484\n",
      "\n",
      "Bigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 1447.6443920650272\n",
      "The sequence the man was happy has perplexity of 1067.0266629370701\n",
      "The sequence the person was good has perplexity of 1495.0416918792678\n",
      "The sequence the girl was sad has perplexity of 3228.92430907225\n",
      "The sequence he won the war has perplexity of 964.0371247036445\n",
      "\n",
      "Trigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 176287178.9389828\n",
      "The sequence the man was happy has perplexity of 1123951.6926896814\n",
      "The sequence the person was good has perplexity of 6740498.8655875465\n",
      "The sequence the girl was sad has perplexity of 3363921.301414764\n",
      "The sequence he won the war has perplexity of 2375816.853522384\n"
     ]
    }
   ],
   "source": [
    "# Additive Smoothing Models for k=1\n",
    "bi_ls=bigram_model(sentences)\n",
    "tri_ls=trigram_model(sentences)\n",
    "k=1\n",
    "from collections import Counter\n",
    "uni_ls=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "u=len(set(unigrams))\n",
    "for word in uni_ls:\n",
    "    uni_ls[word]=(k+uni_ls[word])/(unigram_total+k*u)\n",
    "ubp=(k)/(unigram_total+k*u)\n",
    "\n",
    "for w1 in bi_ls:\n",
    "        tot_count=float(sum(bi_ls[w1].values()))\n",
    "        for w2 in bi_ls[w1]:\n",
    "            bi_ls[w1][w2]=(k+bi_ls[w1][w2])/(tot_count+k*u)\n",
    "\n",
    "for (w1,w2) in tri_ls:\n",
    "        tot_count=float(sum(tri_ls[(w1,w2)].values()))\n",
    "        for w3 in tri_ls[(w1,w2)]:\n",
    "            tri_ls[(w1,w2)][w3]=(k+tri_ls[(w1,w2)][w3])/(k*u+tot_count)\n",
    "\n",
    "print('Additive Smoothing with k='+str(k))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "\n",
    "print('Unigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(uni_ls[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,8)))\n",
    "\n",
    "\n",
    "print('\\nBigram test with Additive Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_ls[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(k/(float(sum(bigram_counts[w1].values()))+k*u))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_ls[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((k/(k*u+float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((k/(k*u)))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "     \n",
    "print('\\nUnigram Perplexity with Additive Smoothing')\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, uni_ls)))\n",
    "    \n",
    "print('\\nBigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def mbiperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(k/(float(sum(bigram_counts[w1].values()))+k*u)))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(mbiperplexity(i, bi_ls)))\n",
    "\n",
    "print('\\nTrigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def ttriperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u+float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ttriperplexity(i, tri_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing with k=0.1\n",
      "Unigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.61509462\n",
      "The sequence the man was happy has unigram log-likelihood of -23.9164008\n",
      "The sequence the person was good has unigram log-likelihood of -23.24210663\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.14544629\n",
      "The sequence he won the war has unigram log-likelihood of -24.55937915\n",
      "\n",
      "Bigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -35.36645242\n",
      "The sequence the man was happy has bigram log-likelihood of -28.43177263\n",
      "The sequence the person was good has bigram log-likelihood of -30.52678498\n",
      "The sequence the girl was sad has bigram log-likelihood of -36.49939055\n",
      "The sequence he won the war has bigram log-likelihood of -27.77381152\n",
      "\n",
      "Trigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -53.81814805\n",
      "The sequence the man was happy has trigram log-likelihood of -42.15146424\n",
      "The sequence the person was good has trigram log-likelihood of -43.58637058\n",
      "The sequence the girl was sad has trigram log-likelihood of -47.16902795\n",
      "The sequence he won the war has trigram log-likelihood of -37.50198373\n",
      "\n",
      "Unigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 680.6300575534524\n",
      "The sequence the man was happy has perplexity of 395.08471059428706\n",
      "The sequence the person was good has perplexity of 333.79487457158746\n",
      "The sequence the girl was sad has perplexity of 885.685191506742\n",
      "The sequence he won the war has perplexity of 463.98154949367876\n",
      "\n",
      "Bigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 363.0021427064168\n",
      "The sequence the man was happy has perplexity of 294.8169117247738\n",
      "The sequence the person was good has perplexity of 448.25263693523505\n",
      "The sequence the girl was sad has perplexity of 1242.4209176173451\n",
      "The sequence he won the war has perplexity of 258.4655210587587\n",
      "\n",
      "Trigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 104348786.40802842\n",
      "The sequence the man was happy has perplexity of 136772.3848259934\n",
      "The sequence the person was good has perplexity of 6942960.366513984\n",
      "The sequence the girl was sad has perplexity of 619558.4590200821\n",
      "The sequence he won the war has perplexity of 184610.00331814899\n"
     ]
    }
   ],
   "source": [
    "# Additive Smoothing Models for k=0.1\n",
    "bi_ls=bigram_model(sentences)\n",
    "tri_ls=trigram_model(sentences)\n",
    "k=0.1\n",
    "from collections import Counter\n",
    "uni_ls=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "u=len(set(unigrams))\n",
    "for word in uni_ls:\n",
    "    uni_ls[word]=(k+uni_ls[word])/(unigram_total+k*u)\n",
    "ubp=(k)/(unigram_total+k*u)\n",
    "\n",
    "for w1 in bi_ls:\n",
    "        tot_count=float(sum(bi_ls[w1].values()))\n",
    "        for w2 in bi_ls[w1]:\n",
    "            bi_ls[w1][w2]=(k+bi_ls[w1][w2])/(tot_count+k*u)\n",
    "\n",
    "for (w1,w2) in tri_ls:\n",
    "        tot_count=float(sum(tri_ls[(w1,w2)].values()))\n",
    "        for w3 in tri_ls[(w1,w2)]:\n",
    "            tri_ls[(w1,w2)][w3]=(k+tri_ls[(w1,w2)][w3])/(k*u+tot_count)\n",
    "\n",
    "print('Additive Smoothing with k='+str(k))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "\n",
    "print('Unigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(uni_ls[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,8)))\n",
    "\n",
    "\n",
    "print('\\nBigram test with Additive Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_ls[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(k/(float(sum(bigram_counts[w1].values()))+k*u))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_ls[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((k/(k*u+float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((k/(k*u)))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "     \n",
    "print('\\nUnigram Perplexity with Additive Smoothing')\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, uni_ls)))\n",
    "    \n",
    "print('\\nBigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def mbiperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(k/(float(sum(bigram_counts[w1].values()))+k*u)))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(mbiperplexity(i, bi_ls)))\n",
    "\n",
    "print('\\nTrigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def ttriperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u+float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ttriperplexity(i, tri_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing with k=0.01\n",
      "Unigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.59590537\n",
      "The sequence the man was happy has unigram log-likelihood of -23.90128863\n",
      "The sequence the person was good has unigram log-likelihood of -23.22608705\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.13482949\n",
      "The sequence he won the war has unigram log-likelihood of -24.54421099\n",
      "\n",
      "Bigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -29.71040845\n",
      "The sequence the man was happy has bigram log-likelihood of -24.39550934\n",
      "The sequence the person was good has bigram log-likelihood of -26.60998627\n",
      "The sequence the girl was sad has bigram log-likelihood of -33.98835464\n",
      "The sequence he won the war has bigram log-likelihood of -23.42543281\n",
      "\n",
      "Trigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -48.83736245\n",
      "The sequence the man was happy has trigram log-likelihood of -37.36084261\n",
      "The sequence the person was good has trigram log-likelihood of -38.76175501\n",
      "The sequence the girl was sad has trigram log-likelihood of -42.31297364\n",
      "The sequence he won the war has trigram log-likelihood of -27.84595823\n",
      "\n",
      "Unigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 678.0229075237785\n",
      "The sequence the man was happy has perplexity of 393.59487998587684\n",
      "The sequence the person was good has perplexity of 332.4607350041083\n",
      "The sequence the girl was sad has perplexity of 883.3375230213098\n",
      "The sequence he won the war has perplexity of 462.2254445877776\n",
      "\n",
      "Bigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 141.42007860737655\n",
      "The sequence the man was happy has perplexity of 131.51249518093405\n",
      "The sequence the person was good has perplexity of 204.79249649830578\n",
      "The sequence the girl was sad has perplexity of 587.2946939676733\n",
      "The sequence he won the war has perplexity of 108.31964832774844\n",
      "\n",
      "Trigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 73190751.97588311\n",
      "The sequence the man was happy has perplexity of 18819.311702928888\n",
      "The sequence the person was good has perplexity of 9073895.750341415\n",
      "The sequence the girl was sad has perplexity of 76004.31397580953\n",
      "The sequence he won the war has perplexity of 6785.374524733131\n"
     ]
    }
   ],
   "source": [
    "# Additive Smoothing Models for k=0.01\n",
    "bi_ls=bigram_model(sentences)\n",
    "tri_ls=trigram_model(sentences)\n",
    "k=0.01\n",
    "from collections import Counter\n",
    "uni_ls=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "u=len(set(unigrams))\n",
    "for word in uni_ls:\n",
    "    uni_ls[word]=(k+uni_ls[word])/(unigram_total+k*u)\n",
    "ubp=(k)/(unigram_total+k*u)\n",
    "\n",
    "for w1 in bi_ls:\n",
    "        tot_count=float(sum(bi_ls[w1].values()))\n",
    "        for w2 in bi_ls[w1]:\n",
    "            bi_ls[w1][w2]=(k+bi_ls[w1][w2])/(tot_count+k*u)\n",
    "\n",
    "for (w1,w2) in tri_ls:\n",
    "        tot_count=float(sum(tri_ls[(w1,w2)].values()))\n",
    "        for w3 in tri_ls[(w1,w2)]:\n",
    "            tri_ls[(w1,w2)][w3]=(k+tri_ls[(w1,w2)][w3])/(k*u+tot_count)\n",
    "\n",
    "print('Additive Smoothing with k='+str(k))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "\n",
    "print('Unigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(uni_ls[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,8)))\n",
    "\n",
    "\n",
    "print('\\nBigram test with Additive Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_ls[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(k/(float(sum(bigram_counts[w1].values()))+k*u))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_ls[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((k/(k*u+float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((k/(k*u)))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "     \n",
    "print('\\nUnigram Perplexity with Additive Smoothing')\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, uni_ls)))\n",
    "    \n",
    "print('\\nBigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def mbiperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(k/(float(sum(bigram_counts[w1].values()))+k*u)))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(mbiperplexity(i, bi_ls)))\n",
    "\n",
    "print('\\nTrigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def ttriperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u+float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ttriperplexity(i, tri_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing with k=0.001\n",
      "Unigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.59398169\n",
      "The sequence the man was happy has unigram log-likelihood of -23.89977364\n",
      "The sequence the person was good has unigram log-likelihood of -23.22448121\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.13376548\n",
      "The sequence he won the war has unigram log-likelihood of -24.54269038\n",
      "\n",
      "Bigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -27.32027061\n",
      "The sequence the man was happy has bigram log-likelihood of -22.48238605\n",
      "The sequence the person was good has bigram log-likelihood of -25.08750661\n",
      "The sequence the girl was sad has bigram log-likelihood of -33.03525774\n",
      "The sequence he won the war has bigram log-likelihood of -21.35969732\n",
      "\n",
      "Trigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -46.78854666\n",
      "The sequence the man was happy has trigram log-likelihood of -34.29235141\n",
      "The sequence the person was good has trigram log-likelihood of -35.26552304\n",
      "The sequence the girl was sad has trigram log-likelihood of -38.04641712\n",
      "The sequence he won the war has trigram log-likelihood of -20.77957714\n",
      "\n",
      "Unigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 677.7620975281864\n",
      "The sequence the man was happy has perplexity of 393.4458353233881\n",
      "The sequence the person was good has perplexity of 332.32729166813056\n",
      "The sequence the girl was sad has perplexity of 883.1025843514434\n",
      "The sequence he won the war has perplexity of 462.0497616471592\n",
      "\n",
      "Bigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 94.95265843295174\n",
      "The sequence the man was happy has perplexity of 89.70057769780212\n",
      "The sequence the person was good has perplexity of 151.03344793414027\n",
      "The sequence the girl was sad has perplexity of 440.076225130505\n",
      "The sequence he won the war has perplexity of 71.66048383987265\n",
      "\n",
      "Trigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 230385332.86090907\n",
      "The sequence the man was happy has perplexity of 8908.654638105856\n",
      "The sequence the person was good has perplexity of 38797135.71155561\n",
      "The sequence the girl was sad has perplexity of 16099.383918696338\n",
      "The sequence he won the war has perplexity of 264.44860305316354\n"
     ]
    }
   ],
   "source": [
    "# Additive Smoothing Models for k=0.001\n",
    "bi_ls=bigram_model(sentences)\n",
    "tri_ls=trigram_model(sentences)\n",
    "k=0.001\n",
    "from collections import Counter\n",
    "uni_ls=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "u=len(set(unigrams))\n",
    "for word in uni_ls:\n",
    "    uni_ls[word]=(k+uni_ls[word])/(unigram_total+k*u)\n",
    "ubp=(k)/(unigram_total+k*u)\n",
    "\n",
    "for w1 in bi_ls:\n",
    "        tot_count=float(sum(bi_ls[w1].values()))\n",
    "        for w2 in bi_ls[w1]:\n",
    "            bi_ls[w1][w2]=(k+bi_ls[w1][w2])/(tot_count+k*u)\n",
    "\n",
    "for (w1,w2) in tri_ls:\n",
    "        tot_count=float(sum(tri_ls[(w1,w2)].values()))\n",
    "        for w3 in tri_ls[(w1,w2)]:\n",
    "            tri_ls[(w1,w2)][w3]=(k+tri_ls[(w1,w2)][w3])/(k*u+tot_count)\n",
    "\n",
    "print('Additive Smoothing with k='+str(k))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "\n",
    "print('Unigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(uni_ls[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,8)))\n",
    "\n",
    "\n",
    "print('\\nBigram test with Additive Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_ls[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(k/(float(sum(bigram_counts[w1].values()))+k*u))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_ls[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((k/(k*u+float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((k/(k*u)))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "     \n",
    "print('\\nUnigram Perplexity with Additive Smoothing')\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, uni_ls)))\n",
    "    \n",
    "print('\\nBigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def mbiperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(k/(float(sum(bigram_counts[w1].values()))+k*u)))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(mbiperplexity(i, bi_ls)))\n",
    "\n",
    "print('\\nTrigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def ttriperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u+float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ttriperplexity(i, tri_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing with k=0.0001\n",
      "Unigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has unigram log-likelihood of -32.59378927\n",
      "The sequence the man was happy has unigram log-likelihood of -23.8996221\n",
      "The sequence the person was good has unigram log-likelihood of -23.22432058\n",
      "The sequence the girl was sad has unigram log-likelihood of -27.13365906\n",
      "The sequence he won the war has unigram log-likelihood of -24.54253828\n",
      "\n",
      "Bigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -26.78768533\n",
      "The sequence the man was happy has bigram log-likelihood of -22.00304228\n",
      "The sequence the person was good has bigram log-likelihood of -24.82092856\n",
      "The sequence the girl was sad has bigram log-likelihood of -34.11102151\n",
      "The sequence he won the war has bigram log-likelihood of -20.87998241\n",
      "\n",
      "Trigram test with Additive Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -47.64450431\n",
      "The sequence the man was happy has trigram log-likelihood of -34.40700904\n",
      "The sequence the person was good has trigram log-likelihood of -34.71683545\n",
      "The sequence the girl was sad has trigram log-likelihood of -35.5428909\n",
      "The sequence he won the war has trigram log-likelihood of -17.17786012\n",
      "\n",
      "Unigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 677.7360155778854\n",
      "The sequence the man was happy has perplexity of 393.4309302405119\n",
      "The sequence the person was good has perplexity of 332.31394704061734\n",
      "The sequence the girl was sad has perplexity of 883.0790887643913\n",
      "The sequence he won the war has perplexity of 462.0321926279583\n",
      "\n",
      "Bigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 86.88750379417478\n",
      "The sequence the man was happy has perplexity of 81.50044307382983\n",
      "The sequence the person was good has perplexity of 143.19190322983454\n",
      "The sequence the girl was sad has perplexity of 538.2083762927297\n",
      "The sequence he won the war has perplexity of 65.10468302260901\n",
      "\n",
      "Trigram Perplexity with Additive Smoothing\n",
      "The sequence he lived a good life has perplexity of 4216239232.6492457\n",
      "The sequence the man was happy has perplexity of 18092.30235000095\n",
      "The sequence the person was good has perplexity of 750166528.6054481\n",
      "The sequence the girl was sad has perplexity of 14137.194198797833\n",
      "The sequence he won the war has perplexity of 23.297434311347686\n"
     ]
    }
   ],
   "source": [
    "# Additive Smoothing Models for k=0.0001\n",
    "bi_ls=bigram_model(sentences)\n",
    "tri_ls=trigram_model(sentences)\n",
    "k=0.0001\n",
    "from collections import Counter\n",
    "uni_ls=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "u=len(set(unigrams))\n",
    "for word in uni_ls:\n",
    "    uni_ls[word]=(k+uni_ls[word])/(unigram_total+k*u)\n",
    "ubp=(k)/(unigram_total+k*u)\n",
    "\n",
    "for w1 in bi_ls:\n",
    "        tot_count=float(sum(bi_ls[w1].values()))\n",
    "        for w2 in bi_ls[w1]:\n",
    "            bi_ls[w1][w2]=(k+bi_ls[w1][w2])/(tot_count+k*u)\n",
    "\n",
    "for (w1,w2) in tri_ls:\n",
    "        tot_count=float(sum(tri_ls[(w1,w2)].values()))\n",
    "        for w3 in tri_ls[(w1,w2)]:\n",
    "            tri_ls[(w1,w2)][w3]=(k+tri_ls[(w1,w2)][w3])/(k*u+tot_count)\n",
    "\n",
    "print('Additive Smoothing with k='+str(k))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_unigram_arr=[]\n",
    "\n",
    "print('Unigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=np.sum([math.log(uni_ls[i]) for i in elem.split()])\n",
    "    test_unigram_arr.append(p_val)\n",
    "    print('The sequence '+elem+' has unigram log-likelihood of '+ str(round(p_val,8)))\n",
    "\n",
    "\n",
    "print('\\nBigram test with Additive Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_ls[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(k/(float(sum(bigram_counts[w1].values()))+k*u))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "\n",
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Additive Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_ls[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((k/(k*u+float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((k/(k*u)))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "     \n",
    "print('\\nUnigram Perplexity with Additive Smoothing')\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(uniperplexity(i, uni_ls)))\n",
    "    \n",
    "print('\\nBigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def mbiperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(k/(float(sum(bigram_counts[w1].values()))+k*u)))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(mbiperplexity(i, bi_ls)))\n",
    "\n",
    "print('\\nTrigram Perplexity with Additive Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def ttriperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u+float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(k/(k*u))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ttriperplexity(i, tri_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Turing Method affecting the lower 10 values and allocating the remanining probability in proportion of the remaining most frequent ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Turing Smoothing for Bigram Model\n",
    "bi_gt=bigram_model(sentences)\n",
    "bili=[]\n",
    "co=0\n",
    "for c in bigram_counts.keys():\n",
    "    co+=len(bigram_counts[c])\n",
    "t=0\n",
    "for c in bigram_counts.keys():\n",
    "        for d in bigram_counts[c].keys():\n",
    "            t+=bigram_counts[c][d]\n",
    "bili.append(co*co-t)\n",
    "for i in range(1,12):\n",
    "    temp=0\n",
    "    for c in bigram_counts.keys():\n",
    "        for d in bigram_counts[c].keys():\n",
    "            if bigram_counts[c][d]==i:\n",
    "                temp+=1\n",
    "    bili.append(temp)\n",
    "# To Store the modified counts\n",
    "bi_mod_counts=[]\n",
    "for i in range(1,len(bili)):\n",
    "    bi_mod_counts.append(i*(bili[i]/float(bili[i-1])))\n",
    "# Updating Counts in Model    \n",
    "for c in bi_gt.keys():\n",
    "        for d in bi_gt[c].keys():\n",
    "            if bi_gt[c][d] in range(1,11):\n",
    "                bi_gt[c][d]=bi_mod_counts[bi_gt[c][d]]\n",
    "# Converting Model with Counts to Probabilities\n",
    "for w1 in bi_gt:\n",
    "        tot_count=float(sum(bi_gt[w1].values()))\n",
    "        for w2 in bi_gt[w1]:\n",
    "            bi_gt[w1][w2]=(bi_gt[w1][w2])/(tot_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigram test with Good Turing Smoothing\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -27.71743189\n",
      "The sequence the man was happy has bigram log-likelihood of -20.92721544\n",
      "The sequence the person was good has bigram log-likelihood of -24.83631352\n",
      "The sequence the girl was sad has bigram log-likelihood of -37.02050632\n",
      "The sequence he won the war has bigram log-likelihood of -20.06233468\n",
      "\n",
      "Bigram Perplexity with Good Turing Smoothing\n",
      "The sequence he lived a good life has perplexity of 101.45060014277486\n",
      "The sequence the man was happy has perplexity of 65.72261538248301\n",
      "The sequence the person was good has perplexity of 143.63318233923422\n",
      "The sequence the girl was sad has perplexity of 961.5367459252897\n",
      "The sequence he won the war has perplexity of 55.283082341739174\n"
     ]
    }
   ],
   "source": [
    "print('\\nBigram test with Good Turing Smoothing\\n')\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(bi_gt[w1][w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(bi_mod_counts[0]/(float(sum(bigram_counts[w1].values()))))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n",
    "\n",
    "print('\\nBigram Perplexity with Good Turing Smoothing')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def m1biperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/model[testset[i-1]][testset[i]])\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(bi_mod_counts[0]/(float(sum(bigram_counts[w1].values())))))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(m1biperplexity(i, bi_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Turing Smoothing for Trigrams\n",
    "tri_gt=trigram_model(sentences)\n",
    "trili=[]\n",
    "cou=0\n",
    "for c in trigram_counts.keys():\n",
    "    cou+=len(trigram_counts[c])\n",
    "t=0\n",
    "for c in trigram_counts.keys():\n",
    "        for d in trigram_counts[c].keys():\n",
    "            t+=trigram_counts[c][d]\n",
    "trili.append(cou*cou-t)\n",
    "for i in range(1,12):\n",
    "    temp=0\n",
    "    for c in trigram_counts.keys():\n",
    "        for d in trigram_counts[c].keys():\n",
    "            if trigram_counts[c][d]==i:\n",
    "                temp+=1\n",
    "    trili.append(temp)\n",
    "# To store the modified counts\n",
    "tri_mod_counts=[]\n",
    "for i in range(1,len(trili)):\n",
    "    tri_mod_counts.append(i*(trili[i]/float(trili[i-1])))\n",
    "# Updating the Counts\n",
    "for c in tri_gt.keys():\n",
    "        for d in tri_gt[c].keys():\n",
    "            if tri_gt[c][d] in range(1,11):\n",
    "                tri_gt[c][d]=tri_mod_counts[tri_gt[c][d]]\n",
    "# Converting Model of Counts to Probabilities\n",
    "for (w1,w2) in tri_gt:\n",
    "        tot_count=float(sum(tri_gt[(w1,w2)].values()))\n",
    "        for w3 in tri_gt[(w1,w2)]:\n",
    "            tri_gt[(w1,w2)][w3]=(tri_gt[(w1,w2)][w3])/(tot_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trigram test with Good Turing Smoothing\n",
      "\n",
      "The sequence he lived a good life has trigram log-likelihood of -58.07371875\n",
      "The sequence the man was happy has trigram log-likelihood of -40.27026893\n",
      "The sequence the person was good has trigram log-likelihood of -40.5898134\n",
      "The sequence the girl was sad has trigram log-likelihood of -29.0057064\n",
      "The sequence he won the war has trigram log-likelihood of -17.09546651\n",
      "\n",
      "Trigram Perplexity with Good Turing Smoothing\n",
      "The sequence he lived a good life has perplexity of 3389328978366.3647\n",
      "The sequence the man was happy has perplexity of 92415.79846559363\n",
      "The sequence the person was good has perplexity of 412080362700.0125\n",
      "The sequence the girl was sad has perplexity of 89298.03158603702\n",
      "The sequence he won the war has perplexity of 8.695864839975235\n"
     ]
    }
   ],
   "source": [
    "test_trigram_arr=[]\n",
    "print('\\nTrigram test with Good Turing Smoothing\\n')\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(tri_gt[(w1,w2)][w3])\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                p_val+=math.log((tri_mod_counts[0]/(float(sum(trigram_counts[(w1,w2)].values())))))\n",
    "            except Exception as e:\n",
    "                p_val+=math.log((tri_mod_counts[0]/bi_mod_counts[0]))\n",
    "    print('The sequence '+ elem +' has trigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_trigram_arr.append(p_val)\n",
    "\n",
    "print('\\nTrigram Perplexity with Good Turing Smoothing')\n",
    "#computes perplexity of the trigram model on a testset  \n",
    "def t1triperplexity(testset, model):\n",
    "    testset = testset.split()\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(2,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * pow((1/model[(testset[i-2],testset[i-1])][testset[i]]),1/float(N))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                perplexity = perplexity * pow((1/(tri_mod_counts[0]/(float(sum(trigram_counts[(w1,w2)].values()))))),1/float(N))\n",
    "            except Exception as e:\n",
    "                perplexity = perplexity * pow((1/(tri_mod_counts[0]/(bi_mod_counts[0]))),1/float(N))\n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(t1triperplexity(i, tri_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation of Bigram Model with lambda value 0.2\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -32.40873916\n",
      "The sequence the man was happy has bigram log-likelihood of -26.24928962\n",
      "The sequence the person was good has bigram log-likelihood of -27.22715572\n",
      "The sequence the girl was sad has bigram log-likelihood of -30.10650982\n",
      "The sequence he won the war has bigram log-likelihood of -25.96759924\n"
     ]
    }
   ],
   "source": [
    "print('Interpolation of Bigram Model with lambda value 0.2\\n')\n",
    "\n",
    "lam=0.2\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(lam*bigram[w1][w2]+(1-lam)*unigram[w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(((1-lam)*unigram[w2]))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation of Bigram Model with lambda value 0.5\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -29.33361575\n",
      "The sequence the man was happy has bigram log-likelihood of -24.05734186\n",
      "The sequence the person was good has bigram log-likelihood of -25.93593035\n",
      "The sequence the girl was sad has bigram log-likelihood of -28.95662442\n",
      "The sequence he won the war has bigram log-likelihood of -23.32978181\n"
     ]
    }
   ],
   "source": [
    "print('Interpolation of Bigram Model with lambda value 0.5\\n')\n",
    "\n",
    "lam=0.5\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(lam*bigram[w1][w2]+(1-lam)*unigram[w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(((1-lam)*unigram[w2]))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation of Bigram Model with lambda value 0.8\n",
      "\n",
      "The sequence he lived a good life has bigram log-likelihood of -27.57424179\n",
      "The sequence the man was happy has bigram log-likelihood of -22.66459485\n",
      "The sequence the person was good has bigram log-likelihood of -25.17318529\n",
      "The sequence the girl was sad has bigram log-likelihood of -28.83973905\n",
      "The sequence he won the war has bigram log-likelihood of -21.66946273\n"
     ]
    }
   ],
   "source": [
    "print('Interpolation of Bigram Model with lambda value 0.8\\n')\n",
    "\n",
    "lam=0.8\n",
    "\n",
    "test_bigram_arr=[]\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=0\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val+=math.log(lam*bigram[w1][w2]+(1-lam)*unigram[w2])\n",
    "        except Exception as e:\n",
    "            p_val+=math.log(((1-lam)*unigram[w2]))\n",
    "    print('The sequence '+ elem +' has bigram log-likelihood of '+ str(round(p_val,8)))\n",
    "    \n",
    "    test_bigram_arr.append(p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity with Interpolation of lambda value 0.2\n",
      "The sequence he lived a good life has perplexity of 221.72913544511488\n",
      "The sequence the man was happy has perplexity of 190.53919540280435\n",
      "The sequence the person was good has perplexity of 231.69715296943434\n",
      "The sequence the girl was sad has perplexity of 412.1148052284036\n",
      "The sequence he won the war has perplexity of 180.10136788352423\n"
     ]
    }
   ],
   "source": [
    "lam=0.2\n",
    "print('Bigram Perplexity with Interpolation of lambda value 0.2')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def ibperplexity(testset, model1, model2):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/((lam*model1[testset[i-1]][testset[i]])+((1-lam)*model2[testset[i]])))\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(((1-lam)*model2[testset[i]])))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ibperplexity(i, bigram, unigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity with Interpolation of lambda value 0.5\n",
      "The sequence he lived a good life has perplexity of 132.8121811600024\n",
      "The sequence the man was happy has perplexity of 122.91196559965756\n",
      "The sequence the person was good has perplexity of 178.96425097058838\n",
      "The sequence the girl was sad has perplexity of 327.4465655561572\n",
      "The sequence he won the war has perplexity of 106.2671666232951\n"
     ]
    }
   ],
   "source": [
    "lam=0.5\n",
    "print('Bigram Perplexity with Interpolation of lambda value 0.5')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def ibperplexity(testset, model1, model2):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/((lam*model1[testset[i-1]][testset[i]])+((1-lam)*model2[testset[i]])))\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(((1-lam)*model2[testset[i]])))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ibperplexity(i, bigram, unigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity with Interpolation of lambda value 0.8\n",
      "The sequence he lived a good life has perplexity of 99.05814150633329\n",
      "The sequence the man was happy has perplexity of 93.02971603117257\n",
      "The sequence the person was good has perplexity of 153.643818834768\n",
      "The sequence the girl was sad has perplexity of 319.88060292420886\n",
      "The sequence he won the war has perplexity of 76.2404792740472\n"
     ]
    }
   ],
   "source": [
    "lam=0.8\n",
    "print('Bigram Perplexity with Interpolation of lambda value 0.8')\n",
    "#computes perplexity of the bigram model on a testset  \n",
    "def ibperplexity(testset, model1, model2):\n",
    "    testset = testset.split()\n",
    "    testset = [None] + testset + [None]\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for i in range(1,len(testset)):\n",
    "        N += 1\n",
    "        try:\n",
    "            perplexity = perplexity * (1/((lam*model1[testset[i-1]][testset[i]])+((1-lam)*model2[testset[i]])))\n",
    "        except KeyError:\n",
    "            perplexity = perplexity * (1/(((1-lam)*model2[testset[i]])))\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity\n",
    "\n",
    "for i in test_sentences:\n",
    "    print('The sequence '+i+' has perplexity of '+str(ibperplexity(i, bigram, unigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsys.stdout = orig_stdout\\nf.close()\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
